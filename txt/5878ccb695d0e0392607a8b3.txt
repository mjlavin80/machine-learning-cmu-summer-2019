Like many Americans, the two of us have strong reasons to hope that 2017 is better than recent years. On Nov. 13, 2015, Beatriz’s daughter, Nohemi, was killed in the Paris terror attacks by an Islamic State cell operating out of Brussels. On March 22, 2016, Cameron’s husband, Alexander, and her sister-in-law, Sascha, were murdered at the Brussels Airport by terrorists from the same cell. One hundred and fifty-nine others also died in those attacks, and more than 600 people were injured. The months since have been anguishing for us, and it is tempting to assign blame — to authorities who failed to heed warnings about suspected terrorists, to government policies that prevented effective surveillance and interdiction of the planners, and of course to the Islamic State terrorists who murdered our loved ones. But our primary motivation in taking action is not to blame others. We want to make it less likely that families will suffer similar anguish in the future. It is for this reason that on Jan. 9 we filed a federal civil lawsuit in the Southern District of New York against Twitter for providing support and resources to the Islamic State, leading to the murders of Nohemi, Alexander and Sascha. In the aftermath of Sept. 11, 2001, Congress passed antiterrorism legislation prohibiting any entity or person connected with the United States from providing “material support or resources” to designated foreign terrorist organizations. Typically we think of such entities as those that supply funds, launder money or refine oil, but the law should also apply to entities that provide services, resources and platforms for communications, including Twitter. This is not a decision we made lightly. We are Twitter users. It is one of the most effective platforms to communicate a message instantly, globally and with immediate impact. But it is also one of the platforms most preferred by the Islamic State. The Islamic State, also known as ISIS, and its supporters have used Twitter for recruiting, planning, issuing threats and taking credit for their attacks. Simply put, the Islamic State uses Twitter as a tool of terrorism. It should be denied access to this weapon. “If you want to talk to a terrorist, you don’t need to send an email to anybody,” the F.B.I. director, James B. Comey, said shortly after the Paris attacks. “You just need to follow that terrorist on Twitter, and then maybe engage in Twitter direct messaging with that terrorist.” He added, “it works as a way to crowdsource terrorism, to sell murder.” Government officials have criticized Twitter for allowing terrorists to access the platform. Congressman Ted Poe, chairman of the House Foreign Affairs Subcommittee on Terrorism, nonproliferation and trade, complained in August 2012 about Twitter’s not shutting down terrorist accounts and argued that terrorists using Twitter “is a violation of U.S. law.” In September of that year, Mr. Poe and several other members of Congress wrote to the F.B.I. director asking that he demand that Twitter block accounts of various terrorist groups. Twitter has long promoted the importance of free and open discourse. In June 2014, in a CNN report, a co-founder, Biz Stone, said, “If you want to create a platform that allows for freedom of expression for hundreds of millions of people around the world, you really have to take the good with the bad.” In November 2014, Mother Jones quoted an unnamed Twitter official saying “One man’s terrorist is another man’s freedom fighter.” Yet as the Mother Jones article pointed out, Twitter users “may not impersonate others, publish copyrighted material without consent, release private information about others, or issue specific violent threats.” In a February 2016 statement, Twitter acknowledged that the terrorist threat was changing and said it was adapting to the changes. The company announced that it had suspended more than 125,000 accounts since mid-2015 “for threatening or promoting terrorist acts” and enlarged the teams that review reports related to terrorism. When pertinent, Twitter also says it cooperates with law-enforcement agencies and works with organizations to combat extremist content online. In August, Twitter said it suspended an additional 235,000 accounts associated with terrorism. But we believe that Twitter doesn’t do enough to proactively monitor, identify and remove terrorist-related accounts and hasn’t made an effective or prolonged effort to ensure that the accounts are not re-established. In short, Twitter’s actions are too little, too late. Hany Farid, the chairman of the computer science department at Dartmouth College and senior adviser at the Counter Extremism Project, has suggested one way Twitter could do more. He has developed software that can block terror-related posts on the internet. It could be used to create a database of known extremist content and prevent future uploads of the material on social media. We both used social media platforms, including Twitter, to frantically search for our loved ones in the hours following the attacks. We know that our lawsuit will not diminish the power of social media platforms, but if our taking a stand diminishes the ability of the Islamic State and its demonic brethren to carry out future murderous campaigns, then perhaps we will have spared others the fate of Nohemi, Alexander and Sascha.
After a weeklong blackout, the Sri Lankan government lifted its nationwide ban on social media on Thursday. Facebook and several other platforms had been shut down after days of violence targeting Muslims in the Kandy district, a popular destination for tourists and pilgrims. The violence began after a Sinhalese Buddhist truck driver was killed in a road-rage incident. Buddhist chauvinist groups flocked to the area, and their visits were followed by looting, arson, and attacks on mosques and on businesses operated by Muslims. Anti-Muslim propaganda is pervasive in all types of media in Sinhala, the language of Sri Lanka’s majority Buddhist population. But some pieces of disinformation — like false accounts of Buddhist monks being attacked — spread on social media and were perceived as especially dangerous. So the Sri Lankan government imposed the ban on Facebook, WhatsApp and several other services as a temporary security measure. It remained in effect until Facebook officials traveled to Sri Lanka to make a personal plea to lift it. The Sri Lankan president, Maithripala Sirisena, agreed to end the ban, saying Facebook pledged to work with the government “to prevent hate speech and misuse of the platform.” Critics immediately pointed out that the company has not offered any specific measures to “fix Facebook”. The government is claiming a victory, but blanket social media bans are not a solution to the problem of hate speech. They set a bad precedent for freedom of expression and undermine efforts to spread messages of reconciliation. In Sri Lanka, the time to act was months, if not years, earlier, engaging with all types of media. Facebook and internet penetration in the country is still around 30 percent. It’s just as likely that this violence was organized not only through Facebook and WhatsApp but also through phone calls and words exchanged across a neighbor’s fence. Facebook and WhatsApp are growing fast in Sri Lanka, but they are only a small part of an extremely polarized media world dominated by television and radio. Anti-minority hate speech, particularly against the Tamil minority, has been part of the Sri Lankan political landscape for decades. Now, it’s Muslims, not just Tamils, who have become the target. We have been conducting surveys and qualitative research on how people use mobile phones and the internet around the region for more than a decade. We recently focused on Myanmar to understand better how hate speech spreads. Social media use has grown at a stunning rate in Myanmar since 2014, at the same time that anti-Muslim violence linked to Buddhist chauvinist groups has escalated. We noticed that people usually first encountered false stories in “affinity circles” — messages sent through Facebook or WhatsApp groups. Within those circles, the messages appear as a communication from a trusted friend or relative. Because many people belong to multiple affinity circles, the hate-speech messages would jump from one circle to another, in each case appearing as from a trusted person. In other words, the human factor, not the platform alone, is important. This pattern is consistent with recent research about how falsehoods spread. A study by Sinan Aral at MIT analyzing about 126,000 Twitter “cascades” showed that false stories spread faster and further than true ones, perhaps because of their novelty, and that human beings — people passing along messages to their friends — were more important than bots. When mob-related violence does occur, the government relies on tactics developed during the colonial era: preventing the formation of mobs, usually through curfews, which stop people from gathering in public spaces. The same principle gives Sri Lanka’s telecommunications minister the power to prohibit the transmission or reception of entire categories of messages in emergencies or “in the interest of public safety and tranquillity.” The Facebook ban — a digital curfew — was an extension of that thinking. Sri Lanka does not have legal authority over Facebook, but it does regulate telecom companies, so it ordered them to block access to Facebook and other platforms. Harin Fernando, the telecommunications minister, told The Guardian, “Hate speech is not being controlled by these organizations, and it has become a critical issue globally.” In India and Pakistan, too, social media firms have come under scrutiny or faced outright bans for circulating hate speech. There is no doubt that social media companies need to do more. While Facebook has hired Sinhala-speaking moderators to detect and remove hate speech, its ability to respond to complaints quickly and consistently is limited. Facebook also should not rely on users to report abuse. It should proactively identify and remove hate speech before it spreads widely enough to generate complaints. But focusing too narrowly on one company or platform is a mistake. A foundation of mutual distrust and fear — not access to social media — is the necessary condition for the mobilization of violent mobs. Governments can’t dismantle that foundation alone. Media companies of all kinds must accept responsibility and deploy artificial intelligence and plain old elbow grease to the task. And people of good will must play their part by calling out falsehoods and reporting those responsible. Banning social media after the mobs have started running is mere political theater.